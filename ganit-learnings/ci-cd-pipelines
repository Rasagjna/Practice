name: CI/CD Pipeline - Build, Push, and Deploy
description: |
    This workflow builds a Docker image, pushes it to Amazon ECR, and deploys it using one of two modes: directly to an EC2 instance via SSH, or via Terraform infrastructure as code. The deployment mode is controlled by the DEPLOY_MODE variable. The workflow is triggered on pushes to the main, dev, and feature branches.

on:
    push:
        branches:
            - "main"
            - "dev"
            - "staging"

env:
    ECR_REPOSITORY: service-backend-ai-insights
    IMAGE_TAG: latest
    GOOGLE_CLOUD_PROJECT_ID: treux-health-dev

jobs:
    docker-build-and-push:
        runs-on: ubuntu-latest
        environment: ${{ github.ref_name == 'main' && 'prod' || 'dev' }}
        outputs:
            deploy_mode: ${{ steps.set-deploy-mode.outputs.mode }}
        permissions:
            contents: read
            packages: read

        steps:
            - name: Checkout
              uses: actions/checkout@v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v2

            - name: Configure SSH for GitHub Access
              run: |
                  mkdir -p ~/.ssh
                  echo "${{ secrets.GIT_PRIVATE_SSH_KEY }}" > ~/.ssh/id_ed25519
                  chmod 600 ~/.ssh/id_ed25519
                  ssh-keyscan github.com >> ~/.ssh/known_hosts
                  eval "$(ssh-agent -s)"
                  ssh-add ~/.ssh/id_ed25519
                  echo "SSH_AUTH_SOCK=$SSH_AUTH_SOCK" >> $GITHUB_ENV
              shell: bash

            - name: Debug SSH Agent
              run: |
                  echo "SSH_AUTH_SOCK = $SSH_AUTH_SOCK"
                  ssh-add -l

            - name: Export AWS Credentials to Environment
              run: |
                  echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
                  echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
                  echo "AWS_REGION=${{ secrets.AWS_REGION }}" >> $GITHUB_ENV
                  echo "AWS credentials set with region: ${{ secrets.AWS_REGION }}"

            - name: Configure AWS Credentials
              uses: aws-actions/configure-aws-credentials@v2
              with:
                  aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
                  aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                  aws-region: ${{ secrets.AWS_REGION }}

            - name: Update AWS CLI v2
              run: |
                  sudo /usr/local/aws-cli/v2/current/bin/aws --version || true
                  curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                  unzip awscliv2.zip
                  sudo ./aws/install --update
                  aws --version

            - name: Download model and lookup files from S3
              run: |
                  mkdir -p local-assets/{models,lookup_files,credentials}
                  aws s3 sync s3://testing-assets-dev/lookup_files/lookup_files/ local-assets/lookup_files/
                  aws s3 sync s3://testing-assets-dev/lookup_files/models/ local-assets/models/
                  aws s3 cp s3://testing-assets-dev/application_default_credentials.json local-assets/credentials/application_default_credentials.json
                  ls -R local-assets/

            - name: Configure Google Cloud quota project
              run: |
                  # Check if the credentials file exists
                  if [ -f "local-assets/credentials/application_default_credentials.json" ]; then
                    # Make a backup of the original file
                    cp local-assets/credentials/application_default_credentials.json local-assets/credentials/application_default_credentials.json.bak
                    
                    # Add quota_project_id to the credentials file if it's not already there
                    # Note: This uses jq to properly modify the JSON file
                    jq '. + {"quota_project_id": "${{ env.GOOGLE_CLOUD_PROJECT_ID }}"}' local-assets/credentials/application_default_credentials.json.bak > local-assets/credentials/application_default_credentials.json
                    
                    echo "Added quota_project_id to Google credentials file"
                    # Don't print the file contents as it contains sensitive information
                  else
                    echo "Warning: Google credentials file not found"
                  fi

            - name: Login to Amazon ECR
              id: login-ecr
              uses: aws-actions/amazon-ecr-login@v2

            - name: Echo Docker Build Info
              run: |
                  echo "Starting Docker build and push process..."
                  echo "Repository: ${{ env.ECR_REPOSITORY }}"
                  echo "Image Tag: ${{ env.IMAGE_TAG }}"
                  echo "ECR Registry: ${{ steps.login-ecr.outputs.registry }}"

            - name: Build and Push Docker Image to ECR
              uses: docker/build-push-action@v5
              with:
                  context: .
                  file: docker/Dockerfile
                  push: true
                  tags: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}
                  ssh: default
                  cache-from: type=gha
                  cache-to: type=gha,mode=max
              env:
                  DOCKER_BUILDKIT: 1
              continue-on-error: false

            - name: Acknowledge Docker Push Completion
              run: |
                  echo "‚úÖ Docker image successfully built and pushed to ECR!"
                  echo "Image: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}"

            - name: Set deploy mode
              id: set-deploy-mode
              run: |
                  echo "mode=${{ vars.DEPLOY_MODE }}" >> $GITHUB_OUTPUT
                  echo "Deploy mode set to: ${{ vars.DEPLOY_MODE }}"

    deploy-to-ec2:
        needs: docker-build-and-push
        runs-on: ubuntu-latest
        environment: ${{ github.ref_name == 'main' && 'prod' || 'dev' }}
        if: needs.docker-build-and-push.outputs.deploy_mode == 'ec2'

        steps:
            - name: Print Deployment Mode
              run: 'echo "üöÄ Deployment mode: EC2 Docker"'

            - name: Set up SSH for EC2 Access
              run: |
                  mkdir -p ~/.ssh
                  echo "${{ secrets.EC2_PRIVATE_SSH_KEY }}" > ~/.ssh/id_rsa
                  chmod 700 ~/.ssh
                  chmod 600 ~/.ssh/id_rsa
                  ssh-keyscan ${{ secrets.EC2_HOST_NAME }} >> ~/.ssh/known_hosts

            - name: Test SSH key permissions
              run: |
                  ls -la ~/.ssh/
                  ssh-keygen -l -f ~/.ssh/id_rsa || echo "Failed to load private key"

            - name: Generate .env file
              run: |
                  cat << EOF > .env
                  ASYNC_SETTINGS__N_WORKERS=${{ vars.ASYNC_SETTINGS__N_WORKERS }}
                  FLAG_ENV_READ_PROPERLY=${{ vars.FLAG_ENV_READ_PROPERLY }}
                  SERVICE_SETTINGS__ENV=${{ vars.SERVICE_SETTINGS__ENV }}
                  SERVICE_SETTINGS__LOG_LEVEL=${{ vars.SERVICE_SETTINGS__LOG_LEVEL }}

                  # Postgres
                  SERVICE_SETTINGS__USE_POSTGRES=${{ vars.SERVICE_SETTINGS__USE_POSTGRES }}
                  DB__DB_NAME=${{ vars.DB__DB_NAME }}
                  DB__SCHEMA_NAMES__SERVICE=${{ vars.DB__SCHEMA_NAMES__SERVICE }}
                  DB__USERNAME=${{ vars.DB__USERNAME }}
                  DB__PASSWORD=${{ vars.DB__PASSWORD }}
                  DB__HOST=${{ vars.DB__HOST }}
                  DB__PORT=${{ vars.DB__PORT }}

                  # Redis
                  REDIS__USERNAME=${{ vars.REDIS__USERNAME }}
                  REDIS__PASSWORD=${{ vars.REDIS__PASSWORD }}
                  REDIS__HOST=${{ vars.REDIS__HOST }}
                  REDIS__PORT=${{ vars.REDIS__PORT }}
                  REDIS__CACHE_TIMEOUT_SEC=${{ vars.REDIS__CACHE_TIMEOUT_SEC }}

                  # AWS Profile
                  AWS_CONFIG__AWS_PROFILE=${{ vars.AWS_CONFIG__AWS_PROFILE }}

                  # Celery
                  CELERY_SETTINGS__ENABLE_BACKGROUND_DOC_PROCESSING=${{ vars.CELERY_SETTINGS__ENABLE_BACKGROUND_DOC_PROCESSING }}
                  MICROSERVICE_DEPS__HEALTH_APP__BASE_URL=${{ vars.MICROSERVICE_DEPS__HEALTH_APP__BASE_URL }}
                  MICROSERVICE_DEPS__DOCTOR_APP__BASE_URL=${{ vars.MICROSERVICE_DEPS__DOCTOR_APP__BASE_URL }}
                  MICROSERVICE_DEPS__HEALTH_APP__SERVICE_NAME=${{ vars.MICROSERVICE_DEPS__HEALTH_APP__SERVICE_NAME }}
                  MICROSERVICE_DEPS__DOCTOR_APP__SERVICE_NAME=${{ vars.MICROSERVICE_DEPS__DOCTOR_APP__SERVICE_NAME }}

                  # S3 Buckets
                  AWS_CONFIG__S3_BUCKET_NAMES__HEALTHAPP_USER_UPLOAD=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__HEALTHAPP_USER_UPLOAD }}
                  AWS_CONFIG__S3_BUCKET_NAMES__PATIENT_DOCUMENT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__PATIENT_DOCUMENT_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__PATIENT_TEXTRACT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__PATIENT_TEXTRACT_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_PROFILE_PHOTO_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_PROFILE_PHOTO_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_DOCUMENT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_DOCUMENT_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_TEXTRACT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__FACILITY_TEXTRACT_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__UNPROFILED_DOCUMENT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__UNPROFILED_DOCUMENT_STORAGE_BUCKET }}
                  AWS_CONFIG__S3_BUCKET_NAMES__UNPROFILED_TEXTRACT_STORAGE_BUCKET=${{ vars.AWS_CONFIG__S3_BUCKET_NAMES__UNPROFILED_TEXTRACT_STORAGE_BUCKET }}

                  # AI Modules
                  PATH_DIR_MODEL_FILES=${{ vars.PATH_DIR_MODEL_FILES }}
                  PATH_DIR_LOOKUP_FILES=${{ vars.PATH_DIR_LOOKUP_FILES }}
                  PATH_TMP_DIR=${{ vars.PATH_TMP_DIR }}

                  GOOGLE_APPLICATION_CREDENTIALS=${{ vars.GOOGLE_APPLICATION_CREDENTIALS }}
                  GOOGLE_CLIENT_ID=${{ secrets.GOOGLE_CLIENT_ID }}
                  GOOGLE_CLIENT_SECRET=${{ secrets.GOOGLE_CLIENT_SECRET }}
                  GOOGLE_REFRESH_TOKEN=${{ secrets.GOOGLE_REFRESH_TOKEN }}
                  GOOGLE_CLOUD_QUOTA_PROJECT=${{ env.GOOGLE_CLOUD_PROJECT_ID }}

                  # Logging
                  AWS_CONFIG__CLOUDWATCH__LOG_GROUP_NAME=${{ vars.AWS_CONFIG__CLOUDWATCH__LOG_GROUP_NAME }}
                  AWS_CONFIG__CLOUDWATCH__STREAM_NAME=${{ vars.AWS_CONFIG__CLOUDWATCH__STREAM_NAME }}
                  AWS_CONFIG__CLOUDWATCH__STREAM_NAME_CELERY=${{ vars.AWS_CONFIG__CLOUDWATCH__STREAM_NAME_CELERY }}

                  # Dev Flags
                  DEV_CONFIG__FLAG_USE_LOCAL_DEV_FLAGS=${{ vars.DEV_CONFIG__FLAG_USE_LOCAL_DEV_FLAGS }}
                  DEV_CONFIG__CACHE_TEXTRACT_RESPONSE_USING_IMG_HASH=${{ vars.DEV_CONFIG__CACHE_TEXTRACT_RESPONSE_USING_IMG_HASH }}
                  EOF

                  echo "Created .env file in workspace"

            - name: Transfer .env to EC2
              run: |
                  scp -i ~/.ssh/id_rsa .env ubuntu@${{ secrets.EC2_HOST_NAME }}:/tmp/service-ai-core.env && \
                  echo "‚úÖ .env file successfully transferred to EC2" || \
                  (echo "‚ùå Failed to transfer .env file to EC2" && exit 1)

            - name: Deploy on EC2
              env:
                  DOCKER_IMAGE: ${{ secrets.ECR_REGISTRY }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}
                  DOCKER_NETWORK: ${{ vars.DOCKER_NETWORK }}
              run: |
                  echo "Starting deployment on EC2..."
                  ssh -i ~/.ssh/id_rsa ubuntu@${{ secrets.EC2_HOST_NAME }} << EOF
                    set -e
                    echo "üîç Checking if Docker is installed..."
                    if ! command -v docker &> /dev/null; then
                      echo "‚öôÔ∏è Installing Docker..."
                      sudo apt-get update
                      sudo apt-get install -y ca-certificates curl gnupg
                      sudo install -m 0755 -d /etc/apt/keyrings
                      curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo tee /etc/apt/keyrings/docker.asc > /dev/null
                      sudo chmod a+r /etc/apt/keyrings/docker.asc
                      echo \
                        "deb [arch=\$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
                        \$(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
                        sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
                      sudo apt-get update
                      sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
                      echo "‚úÖ Docker installation completed."
                    else
                      echo "‚úÖ Docker already installed."
                    fi

                    echo "Logging into ECR..."
                    if aws ecr get-login-password --region ap-south-1 | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}; then
                      echo "‚úÖ Logged into ECR successfully."
                    else
                      echo "‚ùå ECR login failed."
                      exit 1
                    fi

                    echo "Stopping existing Docker containers if running..."
                    docker stop service-ai-core || echo "No running service-ai-core container to stop."
                    docker rm service-ai-core || echo "No service-ai-core container to remove."
                    docker stop service-ai-celery || echo "No running service-ai-celery container to stop."
                    docker rm service-ai-celery || echo "No service-ai-celery container to remove."

                    echo "Pulling latest Docker image..."
                    docker pull $DOCKER_IMAGE || {
                      echo "‚ùå Failed to pull Docker image."
                      exit 1
                    }

                    echo "Starting new Docker container..."
                    docker run -d \
                      --name service-ai-core \
                      --network ${DOCKER_NETWORK} \
                      --env-file /tmp/service-ai-core.env \
                      -v ~/.aws:/home/appuser/.aws:ro \
                      -p 8002:8002 \
                      ${DOCKER_IMAGE}

                    echo "Starting Celery worker container..."
                    docker run -d \
                      --name service-ai-celery \
                      --network ${DOCKER_NETWORK} \
                      --env-file /tmp/service-ai-core.env \
                      -v ~/.aws:/home/appuser/.aws:ro \
                      ${DOCKER_IMAGE} \
                      celery_worker

                    echo "‚úÖ Both containers started successfully. You can view logs with:"
                    echo "docker logs -f service-ai-core"
                    echo "docker logs -f service-ai-celery"

                    echo "Pruning unused Docker images..."
                    docker image prune -f

                    echo "üßπ Cleaning up temporary .env file..."
                    rm -f /tmp/service-ai-core.env && echo "‚úÖ .env file deleted."

                    echo "‚úÖ Deployment script completed successfully on EC2."
                    
                  EOF

    terraform-deploy:
        needs: docker-build-and-push
        runs-on: ubuntu-latest
        environment: ${{ github.ref_name == 'main' && 'prod' || 'dev' }}
        if: needs.docker-build-and-push.outputs.deploy_mode == 'terraform'
        env:
            TF_VAR_environment: ${{ github.ref_name == 'main' && 'prod' || 'dev' }}

        steps:
            - name: Print Deployment Mode
              run: 'echo "üöÄ Deployment mode: Terraform"'

            - name: Checkout
              uses: actions/checkout@v4

            - name: Set up Terraform
              uses: hashicorp/setup-terraform@v2
              with:
                  terraform_version: 1.12.0

            - name: Configure AWS Credentials
              uses: aws-actions/configure-aws-credentials@v2
              with:
                  aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
                  aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                  aws-region: ${{ secrets.AWS_REGION }}

            # --- SHARED INFRASTRUCTURE STEPS ---
            - name: Generate shared.tfvars from Secret
              run: |
                  set -e  # Exit on any error
                  echo '${{ secrets.SHARED_TF_VARS_FILE }}' > .infra/terraform/shared/shared.tfvars
                  echo "‚úÖ shared.tfvars file generated successfully!"

            - name: Terraform Init (shared)
              working-directory: .infra/terraform/shared
              run: |
                  echo "Using backend config for environment: $TF_VAR_environment"
                  terraform init -backend-config="backend-config/$TF_VAR_environment.hcl"

            - name: Terraform Validate (shared)
              working-directory: .infra/terraform/shared
              run: terraform validate

            - name: Terraform Plan (shared)
              id: plan-shared
              working-directory: .infra/terraform/shared
              run: terraform plan -var-file=shared.tfvars -out=plan.out

            - name: Terraform Apply (shared)
              id: tf-shared-apply
              if: success() && steps.plan-shared.outcome == 'success'
              working-directory: .infra/terraform/shared
              run: |
                  set -e
                  terraform apply -auto-approve -var-file=shared.tfvars
                  echo "‚úÖ Shared infrastructure applied successfully!"

            # --- SERVICE-AI-INSIGHTS INFRASTRUCTURE STEPS ---
            - name: Generate service-ai-insights.tfvars from Secret
              run: |
                  set -e  # Exit on any error
                  echo '${{ secrets.SERVICE_TF_VARS_FILE }}' > .infra/terraform/service-ai-insights/terraform.tfvars
                  echo "‚úÖ terraform.tfvars file generated successfully!"

            - name: Terraform Init (service-ai-insights)
              working-directory: .infra/terraform/service-ai-insights
              run: |
                  echo "Using backend config for environment: $TF_VAR_environment"
                  terraform init -backend-config="backend-config/$TF_VAR_environment.hcl"

            - name: Terraform Validate (service-ai-insights)
              working-directory: .infra/terraform/service-ai-insights
              run: terraform validate

            - name: Terraform Plan (service-ai-insights)
              id: plan-service
              working-directory: .infra/terraform/service-ai-insights
              run: terraform plan -var-file=terraform.tfvars -out=plan.out

            - name: Terraform Apply (service-ai-insights)
              id: tf-core-apply
              if: success() && steps.plan-service.outcome == 'success'
              working-directory: .infra/terraform/service-ai-insights
              run: |
                  set -e
                  terraform apply -auto-approve -var-file=terraform.tfvars
                  echo "‚úÖ service-ai-insights infrastructure applied successfully!"

            # --- ECS REDEPLOYMENT STEPS ---
            - name: Force ECS Service Redeploy
              id: ecs-redeploy
              run: |
                  set -e

                  echo "Checking if ECS service '${{ vars.TF_VAR_ECS_SERVICE_NAME }}' exists in cluster '${{ vars.TF_VAR_ECS_CLUSTER_NAME }}'..."

                    SERVICE_EXISTS=$(aws ecs describe-services \
                    --cluster "${{ vars.TF_VAR_ECS_CLUSTER_NAME }}" \
                    --services "${{ vars.TF_VAR_ECS_SERVICE_NAME }}" \
                    --query "services[].serviceName" \
                    --output text)

                  if [ "$SERVICE_EXISTS" = "${{ vars.TF_VAR_ECS_SERVICE_NAME }}" ]; then
                    echo "Service exists. Forcing new deployment..."
                    aws ecs update-service \
                      --cluster "${{ vars.TF_VAR_ECS_CLUSTER_NAME }}" \
                      --service "${{ vars.TF_VAR_ECS_SERVICE_NAME }}" \
                      --force-new-deployment
                    echo "Deployment triggered successfully."
                  else
                    echo "Service '${{ vars.TF_VAR_ECS_SERVICE_NAME }}' does not exist. Skipping redeploy."
                  fi

            - name: Deployment Acknowledgment
              run: |
                  echo "‚úÖ Terraform deployment completed successfully!"
                  echo "üöÄ Infrastructure changes applied"
                  echo "üîÑ ECS service redeployed"
                  echo "Environment: $TF_VAR_environment"
                  echo "Deployment timestamp: $(date)"
